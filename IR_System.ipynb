{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR System.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YIsfYyml0YyU",
        "N6tpMT7p0rQ-",
        "XhKwDRZH0w-n",
        "4DZMkLvH2HOk",
        "TRElhh8-2c6K",
        "X0H6c7MG2qrO"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIsfYyml0YyU"
      },
      "source": [
        "# **Importing Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfPKEq6k8S17",
        "outputId": "74686b5e-e2ae-45f6-9ba0-7886d855b8c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import itertools\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import scipy\n",
        "from scipy import spatial\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "import re\n",
        "tokenizer = ToktokTokenizer()\n",
        "stopword_list = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6tpMT7p0rQ-"
      },
      "source": [
        "# **Creating Sample Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92XoKpWO8eqs"
      },
      "source": [
        "Doc1 = [\"With the Union cabinet approving the amendments to the Motor Vehicles Act, 2016, those caught for drunken driving will have to have really deep pockets, as the fine payable in court has been enhanced to Rs 10,000 for first-time offenders.\" ]\n",
        "Doc2 = [\"Natural language processing (NLP) is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages,in particular how to program computers to process and analyze large amounts of natural language data.\"]\n",
        "Doc3 = [\"He points out that public transport is very good in Mumbai and New Delhi, where there is a good network of suburban and metro rail systems.\"]\n",
        "Doc4 = [\"But the man behind the wickets at the other end was watching just as keenly. With an affirmative nod from Dhoni,India captain Rohit Sharma promptly asked for a review. Sure enough, the ball would have clipped the top of middle and leg.\"]\n",
        "# Put all the documents in one list\n",
        "fin= Doc1+Doc2+Doc3+Doc4"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhKwDRZH0w-n"
      },
      "source": [
        "# **Downloading Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA4BWTw2-phI",
        "outputId": "90c85e09-8e2f-46b9-9c23-72a7cef0ef3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "!wget wget --header 'Host: storage.googleapis.com' --user-agent 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:80.0) Gecko/20100101 Firefox/80.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8' --header 'Accept-Language: en-US,en;q=0.5' --referer 'https://www.kaggle.com/' --header 'DNT: 1' --header 'Upgrade-Insecure-Requests: 1' 'https://storage.googleapis.com/kaggle-data-sets/6763/9801/compressed/GoogleNews-vectors-negative300.bin.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20201014%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20201014T071912Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=7503f1ecbbe421a0e336362bddae66d2ec2ed04f58915450f0d896c9f29e30a99a9605ad3d02b05b6542a3735b49dd26edea2256be591b2b868f6bbecb1bfa819fb431ba322c2558e368aef8e23952911b819b422c909a6f66ebca0bd0d8e2b8a7f3eacdb9f728c94c1b10745d27681a549313b2b48e7ff80d111cd487979234679ae6af81b52a2d171ffb3045d02d65ff675cae02aca7dbb63f07f4a536c63a591229407f561790690145917cc29b78e07557e13c4f48382f15598252f2eb6e66cff794445bfd9ad6d02a95bafb04601ed99626ab6376475c34f5edee30d7f0289b199f0bd5970d0183b0a4483d4dc3127a0f7a03df5d7db9f0696e14cb9b20' --output-document 'GoogleNews-vectors-negative300.bin.zip'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-14 07:31:52--  http://wget/\n",
            "Resolving wget (wget)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘wget’\n",
            "--2020-10-14 07:31:52--  https://storage.googleapis.com/kaggle-data-sets/6763/9801/compressed/GoogleNews-vectors-negative300.bin.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20201014%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20201014T071912Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=7503f1ecbbe421a0e336362bddae66d2ec2ed04f58915450f0d896c9f29e30a99a9605ad3d02b05b6542a3735b49dd26edea2256be591b2b868f6bbecb1bfa819fb431ba322c2558e368aef8e23952911b819b422c909a6f66ebca0bd0d8e2b8a7f3eacdb9f728c94c1b10745d27681a549313b2b48e7ff80d111cd487979234679ae6af81b52a2d171ffb3045d02d65ff675cae02aca7dbb63f07f4a536c63a591229407f561790690145917cc29b78e07557e13c4f48382f15598252f2eb6e66cff794445bfd9ad6d02a95bafb04601ed99626ab6376475c34f5edee30d7f0289b199f0bd5970d0183b0a4483d4dc3127a0f7a03df5d7db9f0696e14cb9b20\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.128, 108.177.12.128, 74.125.26.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1760926034 (1.6G) [application/zip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.zip’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.64G   157MB/s    in 16s     \n",
            "\n",
            "2020-10-14 07:32:09 (104 MB/s) - ‘GoogleNews-vectors-negative300.bin.zip’ saved [1760926034/1760926034]\n",
            "\n",
            "FINISHED --2020-10-14 07:32:09--\n",
            "Total wall clock time: 16s\n",
            "Downloaded: 1 files, 1.6G in 16s (104 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSWVhelH9JGz",
        "outputId": "c4a84944-27fc-45fd-bcc7-4d1c6e98f73e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "!pip install pyunpack\n",
        "!pip install patool"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyunpack in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: entrypoint2 in /usr/local/lib/python3.6/dist-packages (from pyunpack) (0.2.3)\n",
            "Requirement already satisfied: easyprocess in /usr/local/lib/python3.6/dist-packages (from pyunpack) (0.3)\n",
            "Requirement already satisfied: argparse in /usr/local/lib/python3.6/dist-packages (from entrypoint2->pyunpack) (1.4.0)\n",
            "Requirement already satisfied: patool in /usr/local/lib/python3.6/dist-packages (1.12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfubvOOV9QHk",
        "outputId": "c8081617-00c4-4745-a1a6-6a869a174e13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "!unzip '/content/GoogleNews-vectors-negative300.bin'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/GoogleNews-vectors-negative300.bin\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "Archive:  /content/GoogleNews-vectors-negative300.bin.zip\n",
            "replace GoogleNews-vectors-negative300.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kt-kprp9tzz",
        "outputId": "f2696541-dd8f-4133-d540-7f0e08c1f953",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DZMkLvH2HOk"
      },
      "source": [
        "# **Data Pre-Processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRW-Dkei-cVt"
      },
      "source": [
        "def remove_stopwords(text, is_lower_case=False):\n",
        "  pattern = r'[^a-zA-z0-9\\s]'\n",
        "  text = re.sub(pattern, \", \".join(text),text)\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "  tokens = [token.strip() for token in tokens]\n",
        "  if is_lower_case:\n",
        "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "  else:\n",
        "      filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "      filtered_text = ' '.join(filtered_tokens)\n",
        "  return filtered_text"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyTcW3Ls-seT"
      },
      "source": [
        "def get_embedding(word):\n",
        "  if word in model.wv.vocab:\n",
        "    return model[word]\n",
        "  else:\n",
        "    return np.zeros(300)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR0b64qz_1Yl",
        "outputId": "bc0658dd-718c-425e-a171-c84557380e59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL0BO3Iw-0GT",
        "outputId": "4701eada-4187-4199-bfe7-caf6ff2d7905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "out_dict = {}\n",
        "for sen in fin:\n",
        "  average_vector = (np.mean(np.array([get_embedding(x) for x in nltk.word_tokenize(remove_stopwords(sen))]), axis=0))\n",
        "  dict = { sen : (average_vector) }\n",
        "  out_dict.update(dict)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRElhh8-2c6K"
      },
      "source": [
        "# **Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx2xsvmK_zqT"
      },
      "source": [
        "def get_sim(query_embedding, average_vector_doc):\n",
        "  sim = [(1 - scipy.spatial.distance.cosine(query_embedding,average_vector_doc))]\n",
        "  return sim"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7aeRWsL_7xz"
      },
      "source": [
        "def Ranked_documents(query):\n",
        "  query_words = (np.mean(np.array([get_embedding(x) for x in nltk.word_tokenize(query.lower())],dtype=float), axis=0))\n",
        "  rank = []\n",
        "  for k,v in out_dict.items():\n",
        "    rank.append((k, get_sim(query_words, v)))\n",
        "    rank = sorted(rank,key=lambda t: t[1], reverse=True)\n",
        "    print('Ranked Documents :')\n",
        "  return rank"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W492FlJyFGpD",
        "outputId": "aa0fa1b2-8b1d-4cea-8636-79b2a6816ae0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "fin"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['With the Union cabinet approving the amendments to the Motor Vehicles Act, 2016, those caught for drunken driving will have to have really deep pockets, as the fine payable in court has been enhanced to Rs 10,000 for first-time offenders.',\n",
              " 'Natural language processing (NLP) is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages,in particular how to program computers to process and analyze large amounts of natural language data.',\n",
              " 'He points out that public transport is very good in Mumbai and New Delhi, where there is a good network of suburban and metro rail systems.',\n",
              " 'But the man behind the wickets at the other end was watching just as keenly. With an affirmative nod from Dhoni,India captain Rohit Sharma promptly asked for a review. Sure enough, the ball would have clipped the top of middle and leg.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0H6c7MG2qrO"
      },
      "source": [
        "# **Output**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Eo5PX4wAHSj",
        "outputId": "475ccef7-ea71-4a88-ecac-c110ac236d6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "Ranked_documents(\"cricket\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ranked Documents :\n",
            "Ranked Documents :\n",
            "Ranked Documents :\n",
            "Ranked Documents :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('He points out that public transport is very good in Mumbai and New Delhi, where there is a good network of suburban and metro rail systems.',\n",
              "  [0.12267203208343014]),\n",
              " ('Natural language processing (NLP) is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages,in particular how to program computers to process and analyze large amounts of natural language data.',\n",
              "  [0.10547221998440992]),\n",
              " ('But the man behind the wickets at the other end was watching just as keenly. With an affirmative nod from Dhoni,India captain Rohit Sharma promptly asked for a review. Sure enough, the ball would have clipped the top of middle and leg.',\n",
              "  [0.1053129434174076]),\n",
              " ('With the Union cabinet approving the amendments to the Motor Vehicles Act, 2016, those caught for drunken driving will have to have really deep pockets, as the fine payable in court has been enhanced to Rs 10,000 for first-time offenders.',\n",
              "  [0.10428564731331014])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3Zf7S2AAm00"
      },
      "source": [
        "# **Hosting IR System**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p7gaqTVAKpD",
        "outputId": "63879f62-9465-452f-e406-b03218d2775f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from flask import Flask, jsonify, request\n",
        "import socket\n",
        "print(socket.gethostbyname(socket.gethostname()))\n",
        "import requests, json\n",
        "import threading"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "172.28.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0clGGDBIA8K4",
        "outputId": "304e7980-2618-4ead-bacf-db9dcc5666ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "app = Flask(__name__)\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
        "print('Model.......')\n",
        "\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "  pattern = r'[^a-zA-z0-9\\s]'\n",
        "  text = re.sub(pattern, \", \".join(text),text)\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "  tokens = [token.strip() for token in tokens]\n",
        "  if is_lower_case:\n",
        "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "  else:\n",
        "      filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "      filtered_text = ' '.join(filtered_tokens)\n",
        "  return filtered_text\n",
        "\n",
        "\n",
        "def get_embedding(word):\n",
        "  if word in model.wv.vocab:\n",
        "    return model[word]\n",
        "  else:\n",
        "    return np.zeros(300)\n",
        "\n",
        "\n",
        "out_dict = {}\n",
        "for sen in fin:\n",
        "  average_vector = (np.mean(np.array([get_embedding(x) for x in nltk.word_tokenize(remove_stopwords(sen))]), axis=0))\n",
        "  dict = { sen : (average_vector) }\n",
        "  out_dict.update(dict)\n",
        "\n",
        "def get_sim(query_embedding, average_vector_doc):\n",
        "  sim = [(1 - scipy.spatial.distance.cosine(query_embedding,average_vector_doc))]\n",
        "  return sim\n",
        "\n",
        "def Ranked_documents(query):\n",
        "  query_words = (np.mean(np.array([get_embedding(x) for x in nltk.word_tokenize(query.lower())],dtype=float), axis=0))\n",
        "  rank = []\n",
        "  for k,v in out_dict.items():\n",
        "    rank.append((k, get_sim(query_words, v)))\n",
        "    rank = sorted(rank,key=lambda t: t[1], reverse=True)\n",
        "    print('Ranked Documents :')\n",
        "  return rank\n",
        "\n",
        "\n",
        "@app.route('/rank', methods=['POST'])\n",
        "def predict_sentiment():\n",
        "    text = request.get_json()['text']\n",
        "    print(text)\n",
        "\n",
        "    predictions = Ranked_documents(text)\n",
        "    return jsonify(predictions)\n",
        "\n",
        "threading.Thread(target=app.run, kwargs={'host':'0.0.0.0','port':6000}).start()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model.......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8QZoqHzBh-M",
        "outputId": "51cbfe8a-dbc8-49fb-9511-0297dce546b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
        "data = {\"text\":'''cricket'''}\n",
        "\n",
        "req = requests.post(\"http://172.28.0.2:6000/rank\",  data=json.dumps(data), headers=headers)\n",
        "\n",
        "print(req.status_code)\n",
        "print(req.text)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "172.28.0.2 - - [14/Oct/2020 07:36:03] \"\u001b[37mPOST /rank HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cricket\n",
            "Ranked Documents :\n",
            "Ranked Documents :\n",
            "Ranked Documents :\n",
            "Ranked Documents :\n",
            "200\n",
            "[[\"He points out that public transport is very good in Mumbai and New Delhi, where there is a good network of suburban and metro rail systems.\",[0.12267203208343014]],[\"Natural language processing (NLP) is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages,in particular how to program computers to process and analyze large amounts of natural language data.\",[0.10547221998440992]],[\"But the man behind the wickets at the other end was watching just as keenly. With an affirmative nod from Dhoni,India captain Rohit Sharma promptly asked for a review. Sure enough, the ball would have clipped the top of middle and leg.\",[0.1053129434174076]],[\"With the Union cabinet approving the amendments to the Motor Vehicles Act, 2016, those caught for drunken driving will have to have really deep pockets, as the fine payable in court has been enhanced to Rs 10,000 for first-time offenders.\",[0.10428564731331014]]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}