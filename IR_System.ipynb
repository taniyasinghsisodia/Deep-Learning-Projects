{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR System.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YIsfYyml0YyU",
        "N6tpMT7p0rQ-",
        "XhKwDRZH0w-n",
        "4DZMkLvH2HOk",
        "TRElhh8-2c6K",
        "X0H6c7MG2qrO"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIsfYyml0YyU"
      },
      "source": [
        "# **Importing Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfPKEq6k8S17",
        "outputId": "dfce819a-3b68-4cbe-d207-f9464b8302b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import itertools\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import scipy\n",
        "from scipy import spatial\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "import re\n",
        "tokenizer = ToktokTokenizer()\n",
        "stopword_list = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6tpMT7p0rQ-"
      },
      "source": [
        "# **Creating Sample Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92XoKpWO8eqs"
      },
      "source": [
        "Doc1 = [\"With the Union cabinet approving the amendments to the Motor Vehicles Act, 2016, those caught for drunken driving will have to have really deep pockets, as the fine payable in court has been enhanced to Rs 10,000 for first-time offenders.\" ]\n",
        "Doc2 = [\"Natural language processing (NLP) is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages,in particular how to program computers to process and analyze large amounts of natural language data.\"]\n",
        "Doc3 = [\"He points out that public transport is very good in Mumbai and New Delhi, where there is a good network of suburban and metro rail systems.\"]\n",
        "Doc4 = [\"But the man behind the wickets at the other end was watching just as keenly. With an affirmative nod from Dhoni,India captain Rohit Sharma promptly asked for a review. Sure enough, the ball would have clipped the top of middle and leg.\"]\n",
        "# Put all the documents in one list\n",
        "fin= Doc1+Doc2+Doc3+Doc4"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhKwDRZH0w-n"
      },
      "source": [
        "# **Downloading Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA4BWTw2-phI",
        "outputId": "c1065ac2-e151-400a-cc4a-a5deaec3c85c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "!wget wget --header 'Host: storage.googleapis.com' --user-agent 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:80.0) Gecko/20100101 Firefox/80.0' --header 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8' --header 'Accept-Language: en-US,en;q=0.5' --referer 'https://www.kaggle.com/' --header 'DNT: 1' --header 'Upgrade-Insecure-Requests: 1' 'https://storage.googleapis.com/kaggle-data-sets/6763/9801/compressed/GoogleNews-vectors-negative300.bin.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20201014%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20201014T071912Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=7503f1ecbbe421a0e336362bddae66d2ec2ed04f58915450f0d896c9f29e30a99a9605ad3d02b05b6542a3735b49dd26edea2256be591b2b868f6bbecb1bfa819fb431ba322c2558e368aef8e23952911b819b422c909a6f66ebca0bd0d8e2b8a7f3eacdb9f728c94c1b10745d27681a549313b2b48e7ff80d111cd487979234679ae6af81b52a2d171ffb3045d02d65ff675cae02aca7dbb63f07f4a536c63a591229407f561790690145917cc29b78e07557e13c4f48382f15598252f2eb6e66cff794445bfd9ad6d02a95bafb04601ed99626ab6376475c34f5edee30d7f0289b199f0bd5970d0183b0a4483d4dc3127a0f7a03df5d7db9f0696e14cb9b20' --output-document 'GoogleNews-vectors-negative300.bin.zip'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-14 07:19:53--  http://wget/\n",
            "Resolving wget (wget)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘wget’\n",
            "--2020-10-14 07:19:53--  https://storage.googleapis.com/kaggle-data-sets/6763/9801/compressed/GoogleNews-vectors-negative300.bin.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20201014%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20201014T071912Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=7503f1ecbbe421a0e336362bddae66d2ec2ed04f58915450f0d896c9f29e30a99a9605ad3d02b05b6542a3735b49dd26edea2256be591b2b868f6bbecb1bfa819fb431ba322c2558e368aef8e23952911b819b422c909a6f66ebca0bd0d8e2b8a7f3eacdb9f728c94c1b10745d27681a549313b2b48e7ff80d111cd487979234679ae6af81b52a2d171ffb3045d02d65ff675cae02aca7dbb63f07f4a536c63a591229407f561790690145917cc29b78e07557e13c4f48382f15598252f2eb6e66cff794445bfd9ad6d02a95bafb04601ed99626ab6376475c34f5edee30d7f0289b199f0bd5970d0183b0a4483d4dc3127a0f7a03df5d7db9f0696e14cb9b20\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 172.217.203.128, 142.250.97.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1760926034 (1.6G) [application/zip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.zip’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.64G   115MB/s    in 16s     \n",
            "\n",
            "2020-10-14 07:20:09 (108 MB/s) - ‘GoogleNews-vectors-negative300.bin.zip’ saved [1760926034/1760926034]\n",
            "\n",
            "FINISHED --2020-10-14 07:20:09--\n",
            "Total wall clock time: 16s\n",
            "Downloaded: 1 files, 1.6G in 16s (108 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSWVhelH9JGz",
        "outputId": "c00a43d6-4117-42c7-a794-54fb722dafb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "!pip install pyunpack\n",
        "!pip install patool"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyunpack\n",
            "  Downloading https://files.pythonhosted.org/packages/83/29/020436b1d8e96e5f26fa282b9c3c13a3b456a36b9ea2edc87c5fed008369/pyunpack-0.2.2-py2.py3-none-any.whl\n",
            "Collecting entrypoint2\n",
            "  Downloading https://files.pythonhosted.org/packages/c2/ca/00c8767568924e5c2209da99b6abdeeed9d11cbae2a713d54d041b092a09/entrypoint2-0.2.3-py2.py3-none-any.whl\n",
            "Collecting easyprocess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Collecting argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Installing collected packages: argparse, entrypoint2, easyprocess, pyunpack\n",
            "Successfully installed argparse-1.4.0 easyprocess-0.3 entrypoint2-0.2.3 pyunpack-0.2.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.3MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfubvOOV9QHk",
        "outputId": "7d441da4-b686-42bb-8c66-d7d5957c8ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!unzip '/content/GoogleNews-vectors-negative300.bin'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/GoogleNews-vectors-negative300.bin.zip\n",
            "  inflating: GoogleNews-vectors-negative300.bin  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kt-kprp9tzz",
        "outputId": "64c086b5-6b6c-4f15-855b-01c5c00da777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DZMkLvH2HOk"
      },
      "source": [
        "# **Data Pre-Processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRW-Dkei-cVt"
      },
      "source": [
        "def remove_stopwords(text, is_lower_case=False):\n",
        "  pattern = r'[^a-zA-z0-9\\s]'\n",
        "  text = re.sub(pattern, \", \".join(text),text)\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "  tokens = [token.strip() for token in tokens]\n",
        "  if is_lower_case:\n",
        "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "  else:\n",
        "      filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "      filtered_text = ' '.join(filtered_tokens)\n",
        "  return filtered_text"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyTcW3Ls-seT"
      },
      "source": [
        "def get_embedding(word):\n",
        "  if word in model.wv.vocab:\n",
        "    return model[word]\n",
        "  else:\n",
        "    return np.zeros(300)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR0b64qz_1Yl",
        "outputId": "2bc1f9e1-4297-4eb3-f5a8-4ce9d2a74422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KL0BO3Iw-0GT",
        "outputId": "5a4bea8e-0895-40e3-b40c-94deb2bd3532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "out_dict = {}\n",
        "for sen in fin:\n",
        "  average_vector = (np.mean(np.array([get_embedding(x) for x in nltk.word_tokenize(remove_stopwords(sen))]), axis=0))\n",
        "  dict = { sen : (average_vector) }\n",
        "  out_dict.update(dict)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRElhh8-2c6K"
      },
      "source": [
        "# **Helper Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx2xsvmK_zqT"
      },
      "source": [
        "def get_sim(query_embedding, average_vector_doc):\n",
        "  sim = [(1 - scipy.spatial.distance.cosine(query_embedding,average_vector_doc))]\n",
        "  return sim"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7aeRWsL_7xz"
      },
      "source": [
        "def Ranked_documents(query):\n",
        "  query_words = (np.mean(np.array([get_embedding(x) for x in nltk.word_tokenize(query.lower())],dtype=float), axis=0))\n",
        "  rank = []\n",
        "  for k,v in out_dict.items():\n",
        "    rank.append((k, get_sim(query_words, v)))\n",
        "    rank = sorted(rank,key=lambda t: t[1], reverse=True)\n",
        "    print('Ranked Documents :')\n",
        "  return rank"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W492FlJyFGpD",
        "outputId": "7f6ef42b-f3bc-46c5-9db0-959e0679fa56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "fin"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['With the Union cabinet approving the amendments to the Motor Vehicles Act, 2016, those caught for drunken driving will have to have really deep pockets, as the fine payable in court has been enhanced to Rs 10,000 for first-time offenders.',\n",
              " 'Natural language processing (NLP) is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages,in particular how to program computers to process and analyze large amounts of natural language data.',\n",
              " 'He points out that public transport is very good in Mumbai and New Delhi, where there is a good network of suburban and metro rail systems.',\n",
              " 'But the man behind the wickets at the other end was watching just as keenly. With an affirmative nod from Dhoni,India captain Rohit Sharma promptly asked for a review. Sure enough, the ball would have clipped the top of middle and leg.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0H6c7MG2qrO"
      },
      "source": [
        "# **Output**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Eo5PX4wAHSj",
        "outputId": "0941726f-793e-4a06-b8e4-2df9f2bbf4a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "Ranked_documents(\"cricket\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ranked Documents :\n",
            "Ranked Documents :\n",
            "Ranked Documents :\n",
            "Ranked Documents :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('He points out that public transport is very good in Mumbai and New Delhi, where there is a good network of suburban and metro rail systems.',\n",
              "  [0.12267203208343014]),\n",
              " ('Natural language processing (NLP) is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages,in particular how to program computers to process and analyze large amounts of natural language data.',\n",
              "  [0.10547221998440992]),\n",
              " ('But the man behind the wickets at the other end was watching just as keenly. With an affirmative nod from Dhoni,India captain Rohit Sharma promptly asked for a review. Sure enough, the ball would have clipped the top of middle and leg.',\n",
              "  [0.1053129434174076]),\n",
              " ('With the Union cabinet approving the amendments to the Motor Vehicles Act, 2016, those caught for drunken driving will have to have really deep pockets, as the fine payable in court has been enhanced to Rs 10,000 for first-time offenders.',\n",
              "  [0.10428564731331014])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3Zf7S2AAm00"
      },
      "source": [
        "# **Hosting IR System**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p7gaqTVAKpD",
        "outputId": "23817626-9bf8-4d0d-c073-b43b52bac5ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from flask import Flask, jsonify, request\n",
        "import socket\n",
        "print(socket.gethostbyname(socket.gethostname()))\n",
        "import requests, json\n",
        "import threading"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "172.28.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0clGGDBIA8K4",
        "outputId": "7f2fa02f-16f2-44e9-90bf-0445c7968bab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "app = Flask(__name__)\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
        "print('Model.......')\n",
        "\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "  pattern = r'[^a-zA-z0-9\\s]'\n",
        "  text = re.sub(pattern, \", \".join(text),text)\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "  tokens = [token.strip() for token in tokens]\n",
        "  if is_lower_case:\n",
        "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "  else:\n",
        "      filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "      filtered_text = ' '.join(filtered_tokens)\n",
        "  return filtered_text\n",
        "\n",
        "\n",
        "def get_embedding(word):\n",
        "  if word in model.wv.vocab:\n",
        "    return model[word]\n",
        "  else:\n",
        "    return np.zeros(300)\n",
        "\n",
        "\n",
        "out_dict = {}\n",
        "for sen in fin:\n",
        "  average_vector = (np.mean(np.array([get_embedding(x) for x in nltk.word_tokenize(remove_stopwords(sen))]), axis=0))\n",
        "  dict = { sen : (average_vector) }\n",
        "  out_dict.update(dict)\n",
        "\n",
        "def get_sim(query_embedding, average_vector_doc):\n",
        "  sim = [(1 - scipy.spatial.distance.cosine(query_embedding,average_vector_doc))]\n",
        "  return sim\n",
        "\n",
        "def Ranked_documents(query):\n",
        "  query_words = (np.mean(np.array([get_embedding(x) for x in nltk.word_tokenize(query.lower())],dtype=float), axis=0))\n",
        "  rank = []\n",
        "  for k,v in out_dict.items():\n",
        "    rank.append((k, get_sim(query_words, v)))\n",
        "    rank = sorted(rank,key=lambda t: t[1], reverse=True)\n",
        "    print('Ranked Documents :')\n",
        "  return rank\n",
        "\n",
        "\n",
        "@app.route('/rank', methods=['POST'])\n",
        "def predict_sentiment():\n",
        "    text = request.get_json()['text']\n",
        "    print(text)\n",
        "\n",
        "    predictions = Ranked_documents(text)\n",
        "    return jsonify(predictions)\n",
        "\n",
        "threading.Thread(target=app.run, kwargs={'host':'0.0.0.0','port':6000}).start()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:252: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model.......\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8QZoqHzBh-M",
        "outputId": "c926cc79-16bd-4bd4-a042-5312748d5d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n",
        "data = {\"text\":'''cricket'''}\n",
        "\n",
        "req = requests.post(\"http://172.28.0.2:6000/rank\",  data=json.dumps(data), headers=headers)\n",
        "\n",
        "print(req.status_code)\n",
        "print(req.text)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "172.28.0.2 - - [14/Oct/2020 07:25:18] \"\u001b[37mPOST /rank HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cricket\n",
            "Ranked Documents :\n",
            "Ranked Documents :\n",
            "Ranked Documents :\n",
            "Ranked Documents :\n",
            "200\n",
            "[[\"He points out that public transport is very good in Mumbai and New Delhi, where there is a good network of suburban and metro rail systems.\",[0.12267203208343014]],[\"Natural language processing (NLP) is an area of computer science and artificial intelligence concerned with the interactions between computers and human (natural) languages,in particular how to program computers to process and analyze large amounts of natural language data.\",[0.10547221998440992]],[\"But the man behind the wickets at the other end was watching just as keenly. With an affirmative nod from Dhoni,India captain Rohit Sharma promptly asked for a review. Sure enough, the ball would have clipped the top of middle and leg.\",[0.1053129434174076]],[\"With the Union cabinet approving the amendments to the Motor Vehicles Act, 2016, those caught for drunken driving will have to have really deep pockets, as the fine payable in court has been enhanced to Rs 10,000 for first-time offenders.\",[0.10428564731331014]]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zejukw8nCwNc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}